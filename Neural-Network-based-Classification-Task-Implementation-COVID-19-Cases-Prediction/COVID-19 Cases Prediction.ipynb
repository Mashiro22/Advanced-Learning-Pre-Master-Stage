{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# COVID-19 Cases Prediction",
   "id": "f60cf58396926506"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step0 初始化 SwanLab",
   "id": "8ca0248c2ed23e93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:28:58.082309Z",
     "start_time": "2025-07-23T19:28:57.483462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import swanlab\n",
    "\n",
    "swanlab.init(project=\"COVID-19_Cases_Prediction\")\n"
   ],
   "id": "f2b0f4dd898f24cd",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You can't call merge_settings() after swanlab.init()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mswanlab\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mswanlab\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproject\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCOVID-19_Cases_Prediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/swanlab/data/sdk.py:161\u001B[0m, in \u001B[0;36mSwanLabInitializer.init\u001B[0;34m(self, project, workspace, experiment_name, description, tags, config, logdir, mode, load, public, callbacks, settings, **kwargs)\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03mStart a new run to track and log. Once you have called this function, you can use 'swanlab.log' to log data to\u001B[39;00m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03mthe current run. Meanwhile, you can use 'swanlab.finish' to finish the current run and close the current\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;124;03m    The settings for the current experiment.\u001B[39;00m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;66;03m# 注册settings\u001B[39;00m\n\u001B[0;32m--> 161\u001B[0m \u001B[43mmerge_settings\u001B[49m\u001B[43m(\u001B[49m\u001B[43msettings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m SwanLabRun\u001B[38;5;241m.\u001B[39mis_started():\n\u001B[1;32m    163\u001B[0m     swanlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have already initialized a run, the init function will be ignored\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/swanlab/data/utils.py:61\u001B[0m, in \u001B[0;36mshould_call_before_init.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m SwanLabRun\u001B[38;5;241m.\u001B[39mis_started():\n\u001B[0;32m---> 61\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(text)\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: You can't call merge_settings() after swanlab.init()"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step1 数据预处理",
   "id": "40325c3c48b5c9d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:33.860339Z",
     "start_time": "2025-07-23T19:26:33.475195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据集\n",
    "COVID_train = pd.read_csv(\"covid.train.csv\")\n",
    "COVID_test = pd.read_csv(\"covid.test.csv\")\n",
    "\n",
    "COVID_test"
   ],
   "id": "781977fcde21003b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      id   AL   AK   AZ   AR   CA   CO   CT   FL   GA  ...     shop.2  \\\n",
       "0      0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  52.071090   \n",
       "1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  58.742461   \n",
       "2      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  59.109045   \n",
       "3      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  55.442267   \n",
       "4      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  60.588783   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...        ...   \n",
       "888  888  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  56.762931   \n",
       "889  889  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  57.888461   \n",
       "890  890  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  57.589848   \n",
       "891  891  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  57.966384   \n",
       "892  892  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  55.920650   \n",
       "\n",
       "     restaurant.2  spent_time.2  large_event.2  public_transit.2  anxious.2  \\\n",
       "0        8.624001     29.374792       5.391413          2.754804  19.695098   \n",
       "1       21.720187     41.375784       9.450179          3.150088  22.075715   \n",
       "2       20.123959     40.072556       8.781522          2.888209  23.920870   \n",
       "3       16.083529     36.977612       5.199286          2.575347  21.073800   \n",
       "4       19.503010     42.631236      11.549771          8.530551  15.896575   \n",
       "..            ...           ...            ...               ...        ...   \n",
       "888     21.494159     44.202567      14.996865          2.291745  17.740003   \n",
       "889     16.770893     37.373472       7.169675          2.631595  20.587449   \n",
       "890     16.761311     36.874822      11.046907          1.912310  16.800220   \n",
       "891     22.696669     45.350415      20.343487          2.385330  16.528265   \n",
       "892     17.002257     37.749348       9.955671          1.731796  18.555496   \n",
       "\n",
       "     depressed.2  felt_isolated.2  worried_become_ill.2  worried_finances.2  \n",
       "0      13.685645        24.747837             66.194950           44.873473  \n",
       "1      17.302077        23.559622             57.015009           38.372829  \n",
       "2      18.342506        24.993341             55.291498           38.907257  \n",
       "3      12.087171        18.608723             67.036197           43.142779  \n",
       "4      11.781634        15.065228             61.196518           43.574676  \n",
       "..           ...              ...                   ...                 ...  \n",
       "888    12.822676        18.123344             60.417531           37.156229  \n",
       "889    15.960166        23.710310             58.758735           38.673787  \n",
       "890    13.280423        22.423640             60.934851           43.122513  \n",
       "891    15.092539        17.476063             54.862386           44.016255  \n",
       "892    13.776335        21.217106             66.870763           37.930859  \n",
       "\n",
       "[893 rows x 94 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AL</th>\n",
       "      <th>AK</th>\n",
       "      <th>AZ</th>\n",
       "      <th>AR</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CT</th>\n",
       "      <th>FL</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>shop.2</th>\n",
       "      <th>restaurant.2</th>\n",
       "      <th>spent_time.2</th>\n",
       "      <th>large_event.2</th>\n",
       "      <th>public_transit.2</th>\n",
       "      <th>anxious.2</th>\n",
       "      <th>depressed.2</th>\n",
       "      <th>felt_isolated.2</th>\n",
       "      <th>worried_become_ill.2</th>\n",
       "      <th>worried_finances.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.071090</td>\n",
       "      <td>8.624001</td>\n",
       "      <td>29.374792</td>\n",
       "      <td>5.391413</td>\n",
       "      <td>2.754804</td>\n",
       "      <td>19.695098</td>\n",
       "      <td>13.685645</td>\n",
       "      <td>24.747837</td>\n",
       "      <td>66.194950</td>\n",
       "      <td>44.873473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.742461</td>\n",
       "      <td>21.720187</td>\n",
       "      <td>41.375784</td>\n",
       "      <td>9.450179</td>\n",
       "      <td>3.150088</td>\n",
       "      <td>22.075715</td>\n",
       "      <td>17.302077</td>\n",
       "      <td>23.559622</td>\n",
       "      <td>57.015009</td>\n",
       "      <td>38.372829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.109045</td>\n",
       "      <td>20.123959</td>\n",
       "      <td>40.072556</td>\n",
       "      <td>8.781522</td>\n",
       "      <td>2.888209</td>\n",
       "      <td>23.920870</td>\n",
       "      <td>18.342506</td>\n",
       "      <td>24.993341</td>\n",
       "      <td>55.291498</td>\n",
       "      <td>38.907257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.442267</td>\n",
       "      <td>16.083529</td>\n",
       "      <td>36.977612</td>\n",
       "      <td>5.199286</td>\n",
       "      <td>2.575347</td>\n",
       "      <td>21.073800</td>\n",
       "      <td>12.087171</td>\n",
       "      <td>18.608723</td>\n",
       "      <td>67.036197</td>\n",
       "      <td>43.142779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.588783</td>\n",
       "      <td>19.503010</td>\n",
       "      <td>42.631236</td>\n",
       "      <td>11.549771</td>\n",
       "      <td>8.530551</td>\n",
       "      <td>15.896575</td>\n",
       "      <td>11.781634</td>\n",
       "      <td>15.065228</td>\n",
       "      <td>61.196518</td>\n",
       "      <td>43.574676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.762931</td>\n",
       "      <td>21.494159</td>\n",
       "      <td>44.202567</td>\n",
       "      <td>14.996865</td>\n",
       "      <td>2.291745</td>\n",
       "      <td>17.740003</td>\n",
       "      <td>12.822676</td>\n",
       "      <td>18.123344</td>\n",
       "      <td>60.417531</td>\n",
       "      <td>37.156229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.888461</td>\n",
       "      <td>16.770893</td>\n",
       "      <td>37.373472</td>\n",
       "      <td>7.169675</td>\n",
       "      <td>2.631595</td>\n",
       "      <td>20.587449</td>\n",
       "      <td>15.960166</td>\n",
       "      <td>23.710310</td>\n",
       "      <td>58.758735</td>\n",
       "      <td>38.673787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.589848</td>\n",
       "      <td>16.761311</td>\n",
       "      <td>36.874822</td>\n",
       "      <td>11.046907</td>\n",
       "      <td>1.912310</td>\n",
       "      <td>16.800220</td>\n",
       "      <td>13.280423</td>\n",
       "      <td>22.423640</td>\n",
       "      <td>60.934851</td>\n",
       "      <td>43.122513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.966384</td>\n",
       "      <td>22.696669</td>\n",
       "      <td>45.350415</td>\n",
       "      <td>20.343487</td>\n",
       "      <td>2.385330</td>\n",
       "      <td>16.528265</td>\n",
       "      <td>15.092539</td>\n",
       "      <td>17.476063</td>\n",
       "      <td>54.862386</td>\n",
       "      <td>44.016255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.920650</td>\n",
       "      <td>17.002257</td>\n",
       "      <td>37.749348</td>\n",
       "      <td>9.955671</td>\n",
       "      <td>1.731796</td>\n",
       "      <td>18.555496</td>\n",
       "      <td>13.776335</td>\n",
       "      <td>21.217106</td>\n",
       "      <td>66.870763</td>\n",
       "      <td>37.930859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>893 rows × 94 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:34.250451Z",
     "start_time": "2025-07-23T19:26:34.076126Z"
    }
   },
   "cell_type": "code",
   "source": "COVID_test.iloc[:, :-1].describe()",
   "id": "9f7a023653f20a2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               id          AL          AK          AZ          AR          CA  \\\n",
       "count  893.000000  893.000000  893.000000  893.000000  893.000000  893.000000   \n",
       "mean   446.000000    0.025756    0.024636    0.025756    0.025756    0.024636   \n",
       "std    257.931192    0.158495    0.155100    0.158495    0.158495    0.155100   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%    223.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%    446.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%    669.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max    892.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               CO          CT          FL          GA  ...  \\\n",
       "count  893.000000  893.000000  893.000000  893.000000  ...   \n",
       "mean     0.025756    0.025756    0.024636    0.025756  ...   \n",
       "std      0.158495    0.158495    0.155100    0.158495  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000    0.000000  ...   \n",
       "50%      0.000000    0.000000    0.000000    0.000000  ...   \n",
       "75%      0.000000    0.000000    0.000000    0.000000  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "       work_outside_home.2      shop.2  restaurant.2  spent_time.2  \\\n",
       "count           893.000000  893.000000    893.000000    893.000000   \n",
       "mean             31.513665   55.268628     16.444916     36.165898   \n",
       "std               4.733639    4.350540      5.656828      6.192274   \n",
       "min              18.278377   44.671891      3.837441     21.338425   \n",
       "25%              28.730951   51.594301     13.391769     31.330469   \n",
       "50%              31.525946   55.490325     16.975410     36.213594   \n",
       "75%              35.072704   59.078475     20.584376     41.071035   \n",
       "max              43.105181   63.771097     27.362321     52.045373   \n",
       "\n",
       "       large_event.2  public_transit.2   anxious.2  depressed.2  \\\n",
       "count     893.000000        893.000000  893.000000   893.000000   \n",
       "mean       10.248975          2.369115   17.988147    12.993830   \n",
       "std         4.498845          1.114366    2.207022     1.713143   \n",
       "min         2.334655          0.873986   12.696977     8.462444   \n",
       "25%         6.802860          1.760374   16.406397    11.777101   \n",
       "50%         9.550393          2.146468   17.719760    12.805424   \n",
       "75%        13.372731          2.645314   19.423720    14.091551   \n",
       "max        23.305630          9.118302   27.003564    18.964157   \n",
       "\n",
       "       felt_isolated.2  worried_become_ill.2  \n",
       "count       893.000000            893.000000  \n",
       "mean         19.238723             64.619920  \n",
       "std           2.687435              5.685865  \n",
       "min          13.476209             50.212234  \n",
       "25%          17.197313             60.358203  \n",
       "50%          19.068658             65.148128  \n",
       "75%          21.205695             68.994309  \n",
       "max          26.007557             76.871053  \n",
       "\n",
       "[8 rows x 93 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AL</th>\n",
       "      <th>AK</th>\n",
       "      <th>AZ</th>\n",
       "      <th>AR</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CT</th>\n",
       "      <th>FL</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>work_outside_home.2</th>\n",
       "      <th>shop.2</th>\n",
       "      <th>restaurant.2</th>\n",
       "      <th>spent_time.2</th>\n",
       "      <th>large_event.2</th>\n",
       "      <th>public_transit.2</th>\n",
       "      <th>anxious.2</th>\n",
       "      <th>depressed.2</th>\n",
       "      <th>felt_isolated.2</th>\n",
       "      <th>worried_become_ill.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>893.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>0.024636</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>...</td>\n",
       "      <td>31.513665</td>\n",
       "      <td>55.268628</td>\n",
       "      <td>16.444916</td>\n",
       "      <td>36.165898</td>\n",
       "      <td>10.248975</td>\n",
       "      <td>2.369115</td>\n",
       "      <td>17.988147</td>\n",
       "      <td>12.993830</td>\n",
       "      <td>19.238723</td>\n",
       "      <td>64.619920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.931192</td>\n",
       "      <td>0.158495</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.158495</td>\n",
       "      <td>0.158495</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.158495</td>\n",
       "      <td>0.158495</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.158495</td>\n",
       "      <td>...</td>\n",
       "      <td>4.733639</td>\n",
       "      <td>4.350540</td>\n",
       "      <td>5.656828</td>\n",
       "      <td>6.192274</td>\n",
       "      <td>4.498845</td>\n",
       "      <td>1.114366</td>\n",
       "      <td>2.207022</td>\n",
       "      <td>1.713143</td>\n",
       "      <td>2.687435</td>\n",
       "      <td>5.685865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.278377</td>\n",
       "      <td>44.671891</td>\n",
       "      <td>3.837441</td>\n",
       "      <td>21.338425</td>\n",
       "      <td>2.334655</td>\n",
       "      <td>0.873986</td>\n",
       "      <td>12.696977</td>\n",
       "      <td>8.462444</td>\n",
       "      <td>13.476209</td>\n",
       "      <td>50.212234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.730951</td>\n",
       "      <td>51.594301</td>\n",
       "      <td>13.391769</td>\n",
       "      <td>31.330469</td>\n",
       "      <td>6.802860</td>\n",
       "      <td>1.760374</td>\n",
       "      <td>16.406397</td>\n",
       "      <td>11.777101</td>\n",
       "      <td>17.197313</td>\n",
       "      <td>60.358203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.525946</td>\n",
       "      <td>55.490325</td>\n",
       "      <td>16.975410</td>\n",
       "      <td>36.213594</td>\n",
       "      <td>9.550393</td>\n",
       "      <td>2.146468</td>\n",
       "      <td>17.719760</td>\n",
       "      <td>12.805424</td>\n",
       "      <td>19.068658</td>\n",
       "      <td>65.148128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>669.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.072704</td>\n",
       "      <td>59.078475</td>\n",
       "      <td>20.584376</td>\n",
       "      <td>41.071035</td>\n",
       "      <td>13.372731</td>\n",
       "      <td>2.645314</td>\n",
       "      <td>19.423720</td>\n",
       "      <td>14.091551</td>\n",
       "      <td>21.205695</td>\n",
       "      <td>68.994309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.105181</td>\n",
       "      <td>63.771097</td>\n",
       "      <td>27.362321</td>\n",
       "      <td>52.045373</td>\n",
       "      <td>23.305630</td>\n",
       "      <td>9.118302</td>\n",
       "      <td>27.003564</td>\n",
       "      <td>18.964157</td>\n",
       "      <td>26.007557</td>\n",
       "      <td>76.871053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 93 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:35.432444Z",
     "start_time": "2025-07-23T19:26:34.423857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 去除 ID\n",
    "COVID_train_drop = COVID_train.drop(columns=[\"id\"])\n",
    "COVID_test_drop = COVID_test.drop(columns=[\"id\"])\n",
    "\n",
    "# 分离特征和标签\n",
    "x_train = COVID_train_drop.iloc[:, 40:-1]\n",
    "y_train = COVID_train_drop.iloc[:, -1]\n",
    "x_test = COVID_test_drop.iloc[:, 40:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 归一化特征\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# 划分训练集与验证集\n",
    "# 90% 训练集，10% 验证集\n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "# 三分类标签化\n",
    "# tested_positive:(0,20)为 0\n",
    "# tested_positive:(20,50)为 1\n",
    "# tested_positive:(50,100)为 2\n",
    "def one_hot(labels, num_classes=10):\n",
    "    labels_split = np.where(\n",
    "        labels < 5, 0,\n",
    "        np.where(\n",
    "            labels < 8, 1,\n",
    "            np.where(\n",
    "                labels < 11, 2,\n",
    "                np.where(\n",
    "                    labels < 13, 3,\n",
    "                    np.where(\n",
    "                        labels < 15, 4,\n",
    "                        np.where(\n",
    "                            labels < 18, 5,\n",
    "                            np.where(\n",
    "                                labels < 20, 6,\n",
    "                                np.where(\n",
    "                                    labels < 22, 7,\n",
    "                                    np.where(\n",
    "                                        labels < 25, 8, 9\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return np.eye(num_classes)[labels_split.astype(int).ravel()]\n",
    "\n",
    "\n",
    "# 应用\n",
    "# x_train_split[\"tested_positive\"] = one_hot(x_train_split[\"tested_positive\"], 3)\n",
    "# x_train_split[\"tested_positive.1\"] = one_hot(x_train_split[\"tested_positive.1\"], 3)\n",
    "y_train_split = one_hot(y_train_split)\n",
    "# x_val[\"tested_positive\"] = one_hot(x_val[\"tested_positive\"], 3)\n",
    "# x_val[\"tested_positive.1\"] = one_hot(x_val[\"tested_positive.1\"], 3)\n",
    "y_val = one_hot(y_val)\n",
    "\n",
    "y_val"
   ],
   "id": "ef945a1652b5fbd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step2 定义 Sigmoid 函数和 RMSE 函数 (线性回归预测新冠率)",
   "id": "db8fb372396cb42e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:35.663337Z",
     "start_time": "2025-07-23T19:26:35.659514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)  # sigmoid 的导数\n",
    "\n",
    "\n",
    "def rmse_loss(y_true, y_pred):\n",
    "    \"\"\"均方误差损失（适用于回归任务）\"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))"
   ],
   "id": "1a489d51c275331b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step2 定义 Softmax 函数、 Cross Entropy 函数和 Dropout 函数 (多分类预测的病率范围)",
   "id": "85adf11faa625e0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:35.911568Z",
     "start_time": "2025-07-23T19:26:35.906373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)  # 防止数值爆炸（稳定性技巧）\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-12  # 防止 log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "\n",
    "\n",
    "def dropout(x, p=0.2, dropout_act=True):\n",
    "    if not dropout_act:\n",
    "        return x  # 验证/测试时不做dropout\n",
    "    mask = (np.random.rand(*x.shape) > p).astype(float)\n",
    "    return x * mask / (1.0 - p)  # 反向缩放，保持期望一致\n"
   ],
   "id": "47218510b60839de",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step3 评估函数",
   "id": "e0029f6656bd2f8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:36.053396Z",
     "start_time": "2025-07-23T19:26:36.049282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def predict(x, w, b):\n",
    "#     probs = np.dot(x, w) + b\n",
    "#     return probs\n",
    "\n",
    "def predict(logits):\n",
    "    probs = softmax(logits)\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "\n",
    "def evaluate_accuracy(x, y, w, b, tolerance=1):\n",
    "    y_pred = predict(x, w, b)\n",
    "    return np.mean(abs(y_pred - y) <= tolerance)"
   ],
   "id": "cfadbee6a02ed79d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step4 训练函数 (线性回归)",
   "id": "320cc3c7e69583d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:36.183904Z",
     "start_time": "2025-07-23T19:26:36.177234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_linear_regression(x, y, x_val=None, y_val=None, lr=0.01, epochs=1000):\n",
    "    w = np.zeros(x.shape[1])\n",
    "    b = 0\n",
    "\n",
    "    for epoch in range(epochs + 1):\n",
    "        y_pred = np.dot(x, w) + b\n",
    "        # y_pred = sigmoid(z)\n",
    "\n",
    "        # 损失\n",
    "        loss = rmse_loss(y, y_pred)\n",
    "\n",
    "        # 梯度\n",
    "        dz = y_pred - y\n",
    "        dw = np.dot(x.T, dz) / len(x)\n",
    "        db = np.mean(dz)\n",
    "\n",
    "        # 参数更新\n",
    "        w -= lr * dw\n",
    "        b -= lr * db\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            train_acc = evaluate_accuracy(x, y, w, b)\n",
    "            val_acc = evaluate_accuracy(x_val, y_val, w, b) if x_val is not None else None\n",
    "\n",
    "        # ✅ Swanlab 记录\n",
    "        swanlab.log({\n",
    "            \"train_loss\": loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return w, b"
   ],
   "id": "318a95b2ba20d81f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step4 训练函数 （三层 BP 神经网络）",
   "id": "8f25971ea9946674"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:26:36.299922Z",
     "start_time": "2025-07-23T19:26:36.286208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_bp_network(input_dim, hidden_dim, output_dim):\n",
    "    # 使用正态分布初始化参数\n",
    "    w1 = np.random.randn(input_dim, hidden_dim) * 0.01\n",
    "    b1 = np.zeros((1, hidden_dim))\n",
    "\n",
    "    w2 = np.random.randn(hidden_dim, output_dim) * 0.01\n",
    "    b2 = np.zeros((1, output_dim))\n",
    "\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "\n",
    "def forward(x, w1, b1, w2, b2, dropout_act):\n",
    "    z1 = np.dot(x, w1) + b1  # (n, h)\n",
    "    a1 = sigmoid(z1)  # (n, h)\n",
    "    a1 = dropout(a1, p=0.035, dropout_act=dropout_act)\n",
    "    z2 = np.dot(a1, w2) + b2  # (n, c)\n",
    "    a2 = softmax(z2)  # (n, c)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "\n",
    "def backward(x, y_true, z1, a1, z2, a2, w2):\n",
    "    \"\"\"\n",
    "    x: 输入样本 (n, d)\n",
    "    y_true: one-hot 标签 (n, c)\n",
    "    z1, a1, z2, a2: 前向传播中得到的中间值\n",
    "    w2: 第二层权重，用于反向传播\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "\n",
    "    # 输出层误差（softmax + cross-entropy）\n",
    "    dz2 = (a2 - y_true) / n  # (n, c)\n",
    "    dw2 = np.dot(a1.T, dz2)  # (h, c)\n",
    "    db2 = np.sum(dz2, axis=0, keepdims=True)  # (1, c)\n",
    "\n",
    "    # 隐藏层误差（sigmoid导数 + 链式法则）\n",
    "    da1 = np.dot(dz2, w2.T)  # (n, h)\n",
    "    dz1 = da1 * sigmoid_derivative(a1)  # (n, h)\n",
    "    dw1 = np.dot(x.T, dz1)  # (d, h)\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True)  # (1, h)\n",
    "\n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "\n",
    "def update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    w1 -= lr * dw1\n",
    "    b1 -= lr * db1\n",
    "    w2 -= lr * dw2\n",
    "    b2 -= lr * db2\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "\n",
    "def train_bp_network(\n",
    "        x_train, y_train,\n",
    "        x_val=None, y_val=None,\n",
    "        input_dim=53, hidden_dim=64, output_dim=3,\n",
    "        lr=0.05, epochs=100, batch_size=64, verbose=True\n",
    "):\n",
    "    # 1. 初始化\n",
    "    w1, b1, w2, b2 = init_bp_network(input_dim, hidden_dim, output_dim)\n",
    "    history = {\"train_acc\": [], \"val_acc\": [], \"loss\": []}\n",
    "    n = x_train.shape[0]\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    for epoch in range(epochs + 1):\n",
    "        indices = np.arange(n)\n",
    "        np.random.shuffle(indices)\n",
    "        x_train = x_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        for i in range(0, n, batch_size):\n",
    "            x_batch = x_train[i:i + batch_size]\n",
    "            y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "            z1, a1, z2, a2 = forward(x_batch, w1, b1, w2, b2, dropout_act=True)\n",
    "            dw1, db1, dw2, db2 = backward(x_batch, y_batch, z1, a1, z2, a2, w2)\n",
    "            w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, lr)\n",
    "\n",
    "        if epoch % 50 == 0 or epoch == epochs - 1 or epoch == 1:\n",
    "            _, _, z2_train, a2_train = forward(x_train, w1, b1, w2, b2, dropout_act=False)\n",
    "            train_preds = predict(z2_train)\n",
    "            train_labels = np.argmax(y_train, axis=1)\n",
    "            train_acc = np.mean(train_preds == train_labels)\n",
    "\n",
    "            if x_val is not None and y_val is not None:\n",
    "                _, _, z2_val, _ = forward(x_val, w1, b1, w2, b2, dropout_act=False)\n",
    "                val_preds = predict(z2_val)\n",
    "                val_labels = np.argmax(y_val, axis=1)\n",
    "                val_acc = np.mean(val_preds == val_labels)\n",
    "            else:\n",
    "                val_acc = None\n",
    "\n",
    "        loss = cross_entropy_loss(y_train, a2_train)\n",
    "\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"loss\"].append(loss)\n",
    "\n",
    "        # ✅ Swanlab 记录\n",
    "        swanlab.log({\n",
    "            \"train_loss\": loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"epoch\": epoch,\n",
    "        })\n",
    "\n",
    "        if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch:3d} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Loss: {loss:.4f}\")\n",
    "\n",
    "    return w1, b1, w2, b2, history"
   ],
   "id": "713b6c5abfca544e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step5 训练模型",
   "id": "71198f31ed7ff141"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:28:56.978225Z",
     "start_time": "2025-07-23T19:26:36.408281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w1, b1, w2, b2, history = train_bp_network(\n",
    "    x_train_split, y_train_split,\n",
    "    x_val, y_val,\n",
    "    input_dim=53,\n",
    "    hidden_dim=64,\n",
    "    output_dim=10,\n",
    "    lr=0.13,\n",
    "    epochs=8000,\n",
    "    batch_size=64,\n",
    ")"
   ],
   "id": "9689fabbed307ca5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Acc: 0.2321 | Val Acc: 0.2074 | Loss: 2.2431\n",
      "Epoch 100 | Train Acc: 0.7296 | Val Acc: 0.6741 | Loss: 0.7201\n",
      "Epoch 200 | Train Acc: 0.7535 | Val Acc: 0.6926 | Loss: 0.6037\n",
      "Epoch 300 | Train Acc: 0.7724 | Val Acc: 0.6963 | Loss: 0.5545\n",
      "Epoch 400 | Train Acc: 0.7942 | Val Acc: 0.7111 | Loss: 0.5072\n",
      "Epoch 500 | Train Acc: 0.8008 | Val Acc: 0.7259 | Loss: 0.4807\n",
      "Epoch 600 | Train Acc: 0.8115 | Val Acc: 0.7185 | Loss: 0.4505\n",
      "Epoch 700 | Train Acc: 0.8317 | Val Acc: 0.7333 | Loss: 0.4243\n",
      "Epoch 800 | Train Acc: 0.8321 | Val Acc: 0.7333 | Loss: 0.4052\n",
      "Epoch 900 | Train Acc: 0.8391 | Val Acc: 0.7148 | Loss: 0.3877\n",
      "Epoch 1000 | Train Acc: 0.8477 | Val Acc: 0.7185 | Loss: 0.3714\n",
      "Epoch 1100 | Train Acc: 0.8593 | Val Acc: 0.7370 | Loss: 0.3521\n",
      "Epoch 1200 | Train Acc: 0.8667 | Val Acc: 0.7296 | Loss: 0.3414\n",
      "Epoch 1300 | Train Acc: 0.8737 | Val Acc: 0.7259 | Loss: 0.3236\n",
      "Epoch 1400 | Train Acc: 0.8675 | Val Acc: 0.7296 | Loss: 0.3223\n",
      "Epoch 1500 | Train Acc: 0.8815 | Val Acc: 0.7185 | Loss: 0.3013\n",
      "Epoch 1600 | Train Acc: 0.8893 | Val Acc: 0.7259 | Loss: 0.2876\n",
      "Epoch 1700 | Train Acc: 0.8930 | Val Acc: 0.7333 | Loss: 0.2745\n",
      "Epoch 1800 | Train Acc: 0.9004 | Val Acc: 0.7481 | Loss: 0.2637\n",
      "Epoch 1900 | Train Acc: 0.9070 | Val Acc: 0.7370 | Loss: 0.2557\n",
      "Epoch 2000 | Train Acc: 0.9062 | Val Acc: 0.7333 | Loss: 0.2473\n",
      "Epoch 2100 | Train Acc: 0.9148 | Val Acc: 0.7444 | Loss: 0.2357\n",
      "Epoch 2200 | Train Acc: 0.9189 | Val Acc: 0.7333 | Loss: 0.2281\n",
      "Epoch 2300 | Train Acc: 0.9235 | Val Acc: 0.7296 | Loss: 0.2200\n",
      "Epoch 2400 | Train Acc: 0.9280 | Val Acc: 0.7407 | Loss: 0.2113\n",
      "Epoch 2500 | Train Acc: 0.9321 | Val Acc: 0.7481 | Loss: 0.2044\n",
      "Epoch 2600 | Train Acc: 0.9354 | Val Acc: 0.7519 | Loss: 0.1994\n",
      "Epoch 2700 | Train Acc: 0.9354 | Val Acc: 0.7333 | Loss: 0.1907\n",
      "Epoch 2800 | Train Acc: 0.9420 | Val Acc: 0.7333 | Loss: 0.1862\n",
      "Epoch 2900 | Train Acc: 0.9432 | Val Acc: 0.7407 | Loss: 0.1790\n",
      "Epoch 3000 | Train Acc: 0.9473 | Val Acc: 0.7370 | Loss: 0.1736\n",
      "Epoch 3100 | Train Acc: 0.9486 | Val Acc: 0.7444 | Loss: 0.1679\n",
      "Epoch 3200 | Train Acc: 0.9481 | Val Acc: 0.7333 | Loss: 0.1632\n",
      "Epoch 3300 | Train Acc: 0.9523 | Val Acc: 0.7333 | Loss: 0.1592\n",
      "Epoch 3400 | Train Acc: 0.9560 | Val Acc: 0.7444 | Loss: 0.1559\n",
      "Epoch 3500 | Train Acc: 0.9568 | Val Acc: 0.7370 | Loss: 0.1498\n",
      "Epoch 3600 | Train Acc: 0.9543 | Val Acc: 0.7556 | Loss: 0.1463\n",
      "Epoch 3700 | Train Acc: 0.9593 | Val Acc: 0.7519 | Loss: 0.1397\n",
      "Epoch 3800 | Train Acc: 0.9613 | Val Acc: 0.7667 | Loss: 0.1386\n",
      "Epoch 3900 | Train Acc: 0.9650 | Val Acc: 0.7481 | Loss: 0.1324\n",
      "Epoch 4000 | Train Acc: 0.9675 | Val Acc: 0.7444 | Loss: 0.1276\n",
      "Epoch 4100 | Train Acc: 0.9621 | Val Acc: 0.7370 | Loss: 0.1258\n",
      "Epoch 4200 | Train Acc: 0.9716 | Val Acc: 0.7481 | Loss: 0.1210\n",
      "Epoch 4300 | Train Acc: 0.9741 | Val Acc: 0.7481 | Loss: 0.1186\n",
      "Epoch 4400 | Train Acc: 0.9700 | Val Acc: 0.7481 | Loss: 0.1152\n",
      "Epoch 4500 | Train Acc: 0.9724 | Val Acc: 0.7481 | Loss: 0.1131\n",
      "Epoch 4600 | Train Acc: 0.9761 | Val Acc: 0.7481 | Loss: 0.1086\n",
      "Epoch 4700 | Train Acc: 0.9753 | Val Acc: 0.7481 | Loss: 0.1071\n",
      "Epoch 4800 | Train Acc: 0.9757 | Val Acc: 0.7481 | Loss: 0.1050\n",
      "Epoch 4900 | Train Acc: 0.9765 | Val Acc: 0.7519 | Loss: 0.1019\n",
      "Epoch 5000 | Train Acc: 0.9807 | Val Acc: 0.7519 | Loss: 0.0989\n",
      "Epoch 5100 | Train Acc: 0.9774 | Val Acc: 0.7556 | Loss: 0.0970\n",
      "Epoch 5200 | Train Acc: 0.9798 | Val Acc: 0.7556 | Loss: 0.0948\n",
      "Epoch 5300 | Train Acc: 0.9798 | Val Acc: 0.7481 | Loss: 0.0923\n",
      "Epoch 5400 | Train Acc: 0.9835 | Val Acc: 0.7630 | Loss: 0.0902\n",
      "Epoch 5500 | Train Acc: 0.9802 | Val Acc: 0.7519 | Loss: 0.0898\n",
      "Epoch 5600 | Train Acc: 0.9823 | Val Acc: 0.7519 | Loss: 0.0876\n",
      "Epoch 5700 | Train Acc: 0.9807 | Val Acc: 0.7667 | Loss: 0.0861\n",
      "Epoch 5800 | Train Acc: 0.9802 | Val Acc: 0.7704 | Loss: 0.0829\n",
      "Epoch 5900 | Train Acc: 0.9844 | Val Acc: 0.7667 | Loss: 0.0809\n",
      "Epoch 6000 | Train Acc: 0.9827 | Val Acc: 0.7519 | Loss: 0.0793\n",
      "Epoch 6100 | Train Acc: 0.9815 | Val Acc: 0.7630 | Loss: 0.0796\n",
      "Epoch 6200 | Train Acc: 0.9848 | Val Acc: 0.7556 | Loss: 0.0760\n",
      "Epoch 6300 | Train Acc: 0.9872 | Val Acc: 0.7593 | Loss: 0.0748\n",
      "Epoch 6400 | Train Acc: 0.9827 | Val Acc: 0.7593 | Loss: 0.0734\n",
      "Epoch 6500 | Train Acc: 0.9852 | Val Acc: 0.7444 | Loss: 0.0720\n",
      "Epoch 6600 | Train Acc: 0.9856 | Val Acc: 0.7556 | Loss: 0.0701\n",
      "Epoch 6700 | Train Acc: 0.9872 | Val Acc: 0.7630 | Loss: 0.0689\n",
      "Epoch 6800 | Train Acc: 0.9872 | Val Acc: 0.7556 | Loss: 0.0675\n",
      "Epoch 6900 | Train Acc: 0.9877 | Val Acc: 0.7444 | Loss: 0.0667\n",
      "Epoch 7000 | Train Acc: 0.9885 | Val Acc: 0.7556 | Loss: 0.0643\n",
      "Epoch 7100 | Train Acc: 0.9877 | Val Acc: 0.7593 | Loss: 0.0636\n",
      "Epoch 7200 | Train Acc: 0.9868 | Val Acc: 0.7630 | Loss: 0.0631\n",
      "Epoch 7300 | Train Acc: 0.9877 | Val Acc: 0.7519 | Loss: 0.0610\n",
      "Epoch 7400 | Train Acc: 0.9885 | Val Acc: 0.7444 | Loss: 0.0603\n",
      "Epoch 7500 | Train Acc: 0.9889 | Val Acc: 0.7444 | Loss: 0.0599\n",
      "Epoch 7600 | Train Acc: 0.9901 | Val Acc: 0.7519 | Loss: 0.0582\n",
      "Epoch 7700 | Train Acc: 0.9881 | Val Acc: 0.7444 | Loss: 0.0592\n",
      "Epoch 7800 | Train Acc: 0.9893 | Val Acc: 0.7519 | Loss: 0.0562\n",
      "Epoch 7900 | Train Acc: 0.9914 | Val Acc: 0.7593 | Loss: 0.0543\n",
      "Epoch 7999 | Train Acc: 0.9893 | Val Acc: 0.7481 | Loss: 0.0540\n",
      "Epoch 8000 | Train Acc: 0.9905 | Val Acc: 0.7481 | Loss: 0.0537\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step6 模型推理",
   "id": "5f5d55495a0fe5c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:28:57.377030Z",
     "start_time": "2025-07-23T19:28:57.086605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_submission(x_test, w1, b1, w2, b2):\n",
    "    _, _, z2_pred, a2_pred = forward(x_train, w1, b1, w2, b2, dropout_act=False)\n",
    "    test_preds = predict(z2_pred)\n",
    "\n",
    "    # test_df 中的 PassengerId 是测试集乘客的 ID\n",
    "    submission = pd.DataFrame({\n",
    "        \"tested_positive.2\": test_preds,\n",
    "    })\n",
    "\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"保存完成：submission.csv\")\n",
    "\n",
    "\n",
    "save_submission(x_test, w1, b1, w2, b2)"
   ],
   "id": "9f673860997ca2b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存完成：submission.csv\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
